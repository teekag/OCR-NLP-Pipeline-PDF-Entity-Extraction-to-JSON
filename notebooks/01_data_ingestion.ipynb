{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR-NLP Pipeline: Data Ingestion & OCR\n",
    "\n",
    "This notebook demonstrates the data ingestion and OCR components of the pipeline, showing how scanned documents are processed and converted to text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Add the parent directory to the path so we can import our modules\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.ocr_engine import get_ocr_engine, DocumentProcessor\n",
    "from src.nlp_parser import TextPreprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting Up the Environment\n",
    "\n",
    "First, let's set up our environment and check if we have the necessary dependencies installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check if Tesseract is installed and available\n",
    "import shutil\n",
    "\n",
    "tesseract_path = shutil.which('tesseract')\n",
    "if tesseract_path:\n",
    "    print(f\"Tesseract is installed at: {tesseract_path}\")\n",
    "else:\n",
    "    print(\"Tesseract is not installed or not in PATH. Please install it:\")\n",
    "    print(\"  - Ubuntu/Debian: sudo apt-get install tesseract-ocr\")\n",
    "    print(\"  - macOS: brew install tesseract\")\n",
    "    print(\"  - Windows: Download installer from https://github.com/UB-Mannheim/tesseract/wiki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create sample directories if they don't exist\n",
    "data_dir = Path('../data')\n",
    "samples_dir = data_dir / 'samples'\n",
    "processed_dir = data_dir / 'processed'\n",
    "outputs_dir = Path('../outputs')\n",
    "\n",
    "for dir_path in [samples_dir, processed_dir, outputs_dir]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "print(f\"Sample directory: {samples_dir}\")\n",
    "print(f\"Processed directory: {processed_dir}\")\n",
    "print(f\"Outputs directory: {outputs_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating a Sample Document\n",
    "\n",
    "For demonstration purposes, let's create a simple sample document with text that we can use for OCR testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_sample_image(text, filename, size=(800, 600), font_scale=1, thickness=2):\n",
    "    \"\"\"Create a sample image with text for OCR testing.\"\"\"\n",
    "    # Create a blank image\n",
    "    img = np.ones((size[1], size[0], 3), dtype=np.uint8) * 255\n",
    "    \n",
    "    # Add some text\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    color = (0, 0, 0)  # Black color\n",
    "    \n",
    "    # Split text into lines\n",
    "    lines = text.strip().split('\\n')\n",
    "    y_position = 50\n",
    "    \n",
    "    for line in lines:\n",
    "        cv2.putText(img, line, (50, y_position), font, font_scale, color, thickness)\n",
    "        y_position += 40\n",
    "    \n",
    "    # Save the image\n",
    "    cv2.imwrite(str(filename), img)\n",
    "    return img\n",
    "\n",
    "# Sample invoice text\n",
    "invoice_text = \"\"\"INVOICE #12345\n",
    "Date: 2023-03-21\n",
    "Vendor: Acme Corporation\n",
    "\n",
    "Bill To:\n",
    "John Smith\n",
    "123 Main Street\n",
    "Anytown, CA 12345\n",
    "Email: john.smith@example.com\n",
    "\n",
    "Item        Quantity    Price       Total\n",
    "Widget A    5           $10.00      $50.00\n",
    "Widget B    3           $15.00      $45.00\n",
    "Service X   2 hours     $75.00      $150.00\n",
    "\n",
    "Subtotal:                           $245.00\n",
    "Tax (8%):                           $19.60\n",
    "Total:                              $264.60\n",
    "\n",
    "Payment Terms: Net 30\n",
    "Due Date: 2023-04-20\n",
    "\"\"\"\n",
    "\n",
    "# Create and save the sample image\n",
    "sample_image_path = samples_dir / 'sample_invoice.png'\n",
    "img = create_sample_image(invoice_text, sample_image_path, size=(800, 800), font_scale=0.7)\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(10, 12))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.title('Sample Invoice')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Created sample invoice at: {sample_image_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. OCR Processing with Tesseract\n",
    "\n",
    "Now, let's use our OCR engine to extract text from the sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize Tesseract OCR engine\n",
    "ocr_engine = get_ocr_engine('tesseract', lang='eng')\n",
    "document_processor = DocumentProcessor(ocr_engine)\n",
    "\n",
    "# Process the sample image\n",
    "extracted_text = document_processor.process_image(sample_image_path, preprocess=False)\n",
    "\n",
    "print(\"Extracted Text (without preprocessing):\")\n",
    "print(\"-\" * 50)\n",
    "print(extracted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Image Preprocessing for Better OCR Results\n",
    "\n",
    "Let's demonstrate how preprocessing can improve OCR results, especially for lower quality scans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def add_noise_to_image(image, noise_level=20):\n",
    "    \"\"\"Add noise to an image to simulate a lower quality scan.\"\"\"\n",
    "    # Convert to grayscale if it's a color image\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image.copy()\n",
    "    \n",
    "    # Add Gaussian noise\n",
    "    noise = np.random.normal(0, noise_level, gray.shape).astype(np.uint8)\n",
    "    noisy_img = cv2.add(gray, noise)\n",
    "    \n",
    "    # Add some blur to simulate a low-quality scan\n",
    "    blurred = cv2.GaussianBlur(noisy_img, (3, 3), 0)\n",
    "    \n",
    "    return blurred\n",
    "\n",
    "# Create a noisy version of our sample image\n",
    "img = cv2.imread(str(sample_image_path))\n",
    "noisy_img = add_noise_to_image(img, noise_level=15)\n",
    "noisy_image_path = samples_dir / 'sample_invoice_noisy.png'\n",
    "cv2.imwrite(str(noisy_image_path), noisy_img)\n",
    "\n",
    "# Display the noisy image\n",
    "plt.figure(figsize=(10, 12))\n",
    "plt.imshow(noisy_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Noisy Sample Invoice')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Created noisy sample invoice at: {noisy_image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Process the noisy image without preprocessing\n",
    "extracted_text_noisy = document_processor.process_image(noisy_image_path, preprocess=False)\n",
    "\n",
    "print(\"Extracted Text from Noisy Image (without preprocessing):\")\n",
    "print(\"-\" * 50)\n",
    "print(extracted_text_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Process the noisy image with preprocessing\n",
    "extracted_text_noisy_preprocessed = document_processor.process_image(noisy_image_path, preprocess=True)\n",
    "\n",
    "print(\"Extracted Text from Noisy Image (with preprocessing):\")\n",
    "print(\"-\" * 50)\n",
    "print(extracted_text_noisy_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizing the Preprocessing Steps\n",
    "\n",
    "Let's visualize each step of the preprocessing to understand how it improves OCR quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def visualize_preprocessing_steps(image_path):\n",
    "    \"\"\"Visualize the steps in the preprocessing pipeline.\"\"\"\n",
    "    # Load the image\n",
    "    image = cv2.imread(str(image_path))\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "        cv2.THRESH_BINARY, 11, 2\n",
    "    )\n",
    "    \n",
    "    # Noise removal\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    # Display all steps\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    axes[0, 0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    axes[0, 0].set_title('Original Image')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    axes[0, 1].imshow(gray, cmap='gray')\n",
    "    axes[0, 1].set_title('Grayscale')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    axes[1, 0].imshow(thresh, cmap='gray')\n",
    "    axes[1, 0].set_title('Adaptive Thresholding')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    axes[1, 1].imshow(opening, cmap='gray')\n",
    "    axes[1, 1].set_title('Noise Removal')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return opening\n",
    "\n",
    "# Visualize preprocessing steps for the noisy image\n",
    "preprocessed_img = visualize_preprocessing_steps(noisy_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Text Cleaning and Normalization\n",
    "\n",
    "After OCR, we often need to clean and normalize the extracted text to correct common OCR errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize text preprocessor\n",
    "text_preprocessor = TextPreprocessor()\n",
    "\n",
    "# Clean the extracted text\n",
    "cleaned_text = text_preprocessor.clean_ocr_text(extracted_text_noisy_preprocessed)\n",
    "\n",
    "print(\"Cleaned OCR Text:\")\n",
    "print(\"-\" * 50)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Process the text with all preprocessing steps\n",
    "processed_result = text_preprocessor.process_text(\n",
    "    extracted_text_noisy_preprocessed,\n",
    "    clean=True,\n",
    "    normalize=True,\n",
    "    remove_stopwords=False,\n",
    "    remove_punctuation=False\n",
    ")\n",
    "\n",
    "print(f\"Word count: {processed_result['word_count']}\")\n",
    "print(f\"Number of sentences: {len(processed_result['sentences'])}\")\n",
    "print(f\"Number of paragraphs: {len(processed_result['paragraphs'])}\")\n",
    "\n",
    "print(\"\\nFirst 3 sentences:\")\n",
    "for i, sentence in enumerate(processed_result['sentences'][:3]):\n",
    "    print(f\"{i+1}. {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparing OCR Engines\n",
    "\n",
    "Let's compare the results from different OCR engines (Tesseract vs. EasyOCR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Try to initialize EasyOCR (this may take a while the first time)\n",
    "try:\n",
    "    import easyocr\n",
    "    easyocr_available = True\n",
    "    print(\"EasyOCR is available. Initializing...\")\n",
    "    easy_ocr_engine = get_ocr_engine('easyocr', lang_list=['en'])\n",
    "    easy_document_processor = DocumentProcessor(easy_ocr_engine)\n",
    "except ImportError:\n",
    "    easyocr_available = False\n",
    "    print(\"EasyOCR is not installed. Skipping comparison.\")\n",
    "    print(\"You can install it with: pip install easyocr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "if easyocr_available:\n",
    "    # Process the same image with EasyOCR\n",
    "    easyocr_text = easy_document_processor.process_image(sample_image_path, preprocess=False)\n",
    "    \n",
    "    print(\"EasyOCR Extracted Text:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(easyocr_text)\n",
    "    \n",
    "    # Compare word counts\n",
    "    tesseract_words = len(extracted_text.split())\n",
    "    easyocr_words = len(easyocr_text.split())\n",
    "    \n",
    "    print(f\"\\nComparison:\")\n",
    "    print(f\"Tesseract word count: {tesseract_words}\")\n",
    "    print(f\"EasyOCR word count: {easyocr_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Saving Processed Results\n",
    "\n",
    "Finally, let's save our processed results to the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save the original and processed text\n",
    "with open(processed_dir / 'sample_invoice_original.txt', 'w') as f:\n",
    "    f.write(extracted_text)\n",
    "    \n",
    "with open(processed_dir / 'sample_invoice_processed.txt', 'w') as f:\n",
    "    f.write(cleaned_text)\n",
    "    \n",
    "print(f\"Saved original text to: {processed_dir / 'sample_invoice_original.txt'}\")\n",
    "print(f\"Saved processed text to: {processed_dir / 'sample_invoice_processed.txt'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Next Steps\n",
    "\n",
    "In this notebook, we've demonstrated:\n",
    "\n",
    "1. Setting up the OCR environment\n",
    "2. Creating sample documents for testing\n",
    "3. Extracting text using Tesseract OCR\n",
    "4. Preprocessing images to improve OCR quality\n",
    "5. Cleaning and normalizing OCR output\n",
    "6. Comparing different OCR engines\n",
    "\n",
    "In the next notebook, we'll explore entity extraction and the full pipeline from PDF to structured JSON output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
